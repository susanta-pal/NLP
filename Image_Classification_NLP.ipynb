{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFAgM2+rYgfuWlqlFvkJ1F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susanta-pal/NLP/blob/main/Image_Classification_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "iYhTUEVpYVfU",
        "outputId": "20417fca-2938-4607-c292-18942656acc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>8\n",
            "<class 'int'>7\n",
            "<class 'int'>5\n",
            "95.21\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' End to call '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "This program is a partial MNIST classifier using AlexNet. It accepts three parameters provided as a command line input. The first two inputs are two digits between 0-9 which are used to train and test the classifier and the third parameter controls the number of training epochs.\n",
        "Syntax: python assignment.py <number> <number> <number>\n",
        "\n",
        "For example, to train and test AlexNet with 1 and 2 MNIST samples with 4 training epochs, the command line input should be:\n",
        "python assignment.py 1 2 4\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "ALERT: * * * No changes are allowed to import statements  * * *\n",
        "\"\"\"\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "* * * Changes allowed from here  * * *\n",
        "\"\"\"\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            # Define feature extractor here...\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            # Define classifier here...\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(32*12*12, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define forward network 'x' that combines feature extractor and classifier\n",
        "        x = self.feature(x)\n",
        "        x = x.view(-1,32*12*12)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "ALERT: * * * No changes are allowed after this comment  * * *\n",
        "\"\"\"\n",
        "\n",
        "def load_subset(full_train_set, full_test_set, label_one, label_two):\n",
        "    # Sample the correct train labels\n",
        "    train_set = []\n",
        "    data_lim = 20000\n",
        "    for data in full_train_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                train_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    test_set = []\n",
        "    data_lim = 1000\n",
        "    for data in full_test_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                test_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return train_set, test_set\n",
        "\n",
        "def train(model,optimizer,train_loader,epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()#size_average=False\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
        "    test_accuracy = (acc / len(test_loader.dataset))\n",
        "    return test_accuracy\n",
        "\n",
        "'''if __name__ == '__main__':\n",
        "\n",
        "    if len(sys.argv) == 3:\n",
        "        print(\"Usage: python assignment.py <number> <number>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    input_data_one = sys.argv[1].strip()\n",
        "    input_data_two = sys.argv[2].strip()\n",
        "    epochs = sys.argv[3].strip()'''\n",
        "\n",
        "input_data_one = input(int)\n",
        "input_data_two = input(int)\n",
        "epochs = input(int)\n",
        "\n",
        "\"\"\"  Call to function that will perform the computation. \"\"\"\n",
        "if input_data_one.isdigit() and input_data_two.isdigit() and epochs.isdigit():\n",
        "\n",
        "    label_one = int(input_data_one)\n",
        "    label_two = int(input_data_two)\n",
        "    epochs = int(epochs)\n",
        "\n",
        "    if label_one!=label_two and 0<=label_one<=9 and 0<=label_two<=9:\n",
        "        torch.manual_seed(42)\n",
        "        # Load MNIST dataset\n",
        "        trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "        full_train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
        "        full_test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
        "        batch_size = 16\n",
        "\n",
        "        '''3show = 2\n",
        "        max_show = show\n",
        "        for i in full_train_set:\n",
        "          current_image = i[0][0]\n",
        "          plt.figure(max_show+1-show)\n",
        "          plt.imshow(current_image)\n",
        "          print(current_image.shape)\n",
        "          show-=1\n",
        "          if show==0:\n",
        "            break'''\n",
        "\n",
        "        # Get final train and test sets\n",
        "        train_set, test_set = load_subset(full_train_set,full_test_set,label_one,label_two)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=False)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "        model = AlexNet()\n",
        "        if torch.cuda.is_available():\n",
        "            model.cuda()\n",
        "\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            train(model,optimizer,train_loader,epoch)\n",
        "            accuracy = test(model,test_loader)\n",
        "\n",
        "        print(round(accuracy,2))\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid input\")\n",
        "else:\n",
        "    print(\"Invalid input\")\n",
        "\n",
        "\n",
        "\"\"\" End to call \"\"\""
      ]
    }
  ]
}